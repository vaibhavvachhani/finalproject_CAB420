{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading ratings file\n",
    "ratings = pd.read_csv('ml-20m/ratings.csv', sep=',', \n",
    "                      usecols=['userId', 'movieId', 'rating'])\n",
    "max_userid = ratings['userId'].drop_duplicates().max()\n",
    "max_movieid = ratings['movieId'].drop_duplicates().max()\n",
    "\n",
    "# Reading ratings file\n",
    "movies = pd.read_csv('ml-20m/movies.csv', sep=',', \n",
    "                     usecols=['movieId', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: [ 49018  89527 106704 ... 135700  58198  85916] , shape = (99999,)\n",
      "Movies: [    32 109374   1060 ...   4031   3450   1348] , shape = (99999,)\n",
      "Ratings: [2.  3.5 3.  ... 1.  3.  5. ] , shape = (99999,)\n"
     ]
    }
   ],
   "source": [
    "# Create training set\n",
    "shuffled_ratings = ratings.sample(frac=1., random_state=42)\n",
    "\n",
    "# Shuffling users\n",
    "Users = shuffled_ratings['userId'][1:100000].values\n",
    "print('Users:', Users, ', shape =', Users.shape)\n",
    "\n",
    "# Shuffling movies\n",
    "Movies = shuffled_ratings['movieId'][1:100000].values\n",
    "print('Movies:', Movies, ', shape =', Movies.shape)\n",
    "\n",
    "# Shuffling ratings\n",
    "Ratings = shuffled_ratings['rating'][1:100000].values\n",
    "print('Ratings:', Ratings, ', shape =', Ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras libraries\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "# Import CF Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "K_FACTORS = 100 # The number of dimensional embeddings for movies and users\n",
    "TEST_USER = 2000 # A random test user (user_id = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aidankinzett/.virtualenvs/cab420env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Reshape, dot\n",
    "\n",
    "input_1 = Input(shape=(1,))\n",
    "input_2 = Input(shape=(1,))\n",
    "\n",
    "P = Reshape((K_FACTORS,))(Embedding(max_userid, K_FACTORS, input_length=1)(input_1))\n",
    "Q = Reshape((K_FACTORS,))(Embedding(max_userid, K_FACTORS, input_length=1)(input_2))\n",
    "P_dot_Q = dot([P, Q], axes = 1, normalize = False)\n",
    "\n",
    "model = Model(inputs=[input_1,input_2], outputs=P_dot_Q)\n",
    "#print(model.summary())\n",
    "model.compile(loss = 'MSE', optimizer='adamax',metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aidankinzett/.virtualenvs/cab420env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 89999 samples, validate on 10000 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "# Callbacks monitor the validation loss\n",
    "# Save the model weights each time the validation loss has improved\n",
    "callbacks = [EarlyStopping('val_loss', patience=3), \n",
    "             ModelCheckpoint('weights.h5', save_best_only=True)]\n",
    "\n",
    "# Use 30 epochs, 90% training data, 10% validation data \n",
    "history = model.fit([Users, Movies], Ratings, epochs=30, validation_split=.1, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the best validation RMSE\n",
    "min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "print('Minimum RMSE at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(math.sqrt(min_val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the ratings given User ID and Movie ID\n",
    "def predict_rating(userId, movieId):\n",
    "    return model.predict([np.array([userId - 1]),np.array([movieId - 1])])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_USER = 1456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = ratings[ratings['userId'] == TEST_USER][['userId', 'movieId', 'rating']]\n",
    "user_ratings['prediction'] = user_ratings.apply(lambda x: predict_rating(TEST_USER, x['movieId']), axis=1)\n",
    "user_ratings.sort_values(by='rating', ascending=False).merge(movies, \n",
    "                                                on='movieId', \n",
    "                                                how='inner', \n",
    "                                                suffixes=['_u', '_m']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = ratings[ratings['movieId'].isin(user_ratings['movieId']) == False][['movieId']].drop_duplicates()\n",
    "recommendations['prediction'] = recommendations.apply(lambda x: predict_rating(TEST_USER, x['movieId']), axis=1)\n",
    "recommendations.sort_values(by='prediction',\n",
    "                          ascending=False).merge(movies,\n",
    "                                                 on='movieId',\n",
    "                                                 how='inner',\n",
    "                                                 suffixes=['_u', '_m']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
